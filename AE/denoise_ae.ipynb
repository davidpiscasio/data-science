{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder (AE)\n",
    "In this notebook, we build a CNN-based autoencoder for denoising trained on the MNIST dataset. We used [Deep-Learning-Experiments](https://github.com/roatienza/Deep-Learning-Experiments/blob/master/versions/2022/autoencoder/python/ae_pytorch_demo.ipynb) and [Building a CNN-based Autoencoder with Denoising in Python](https://medium.com/@polanitzer/building-a-cnn-based-autoencoder-with-denoising-in-python-on-gray-scale-images-of-hand-drawn-digits-61131ec492e4) as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics import Accuracy\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from argparse import ArgumentParser\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create the Encoder module of our denoising autoencoder. The parameter num_filters dictates the number of filters in each convolution layer. The kernel sizes of $(3, 3)$ in the convolution layer and $(2,2)$ in the max pooling are consistent throughout all layers. ReLU is used as the activation function for all convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEEncoder(nn.Module):\n",
    "    def __init__(self, img_channels=1, num_filters=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build the CNN layers\n",
    "        self.conv0 = nn.Conv2d(in_channels=img_channels, out_channels=num_filters, kernel_size=3, padding='same')\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_filters, out_channels=num_filters, kernel_size=3, padding='same')\n",
    "        # Build the ReLU activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        # Build the Max Pool layer\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First Convolutional Layer\n",
    "        y = self.conv0(x)\n",
    "        y = self.relu(y)\n",
    "        y = self.maxpool(y)\n",
    "\n",
    "        # Second Convolutional Layer\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.maxpool(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the Decoder module of our denoising autoencoder. Like the encoder, the parameter num_filters dictates the number of filters in each convolution layer and the same kernel size for convolution is consistent throughout all layers. We have substituted the max pool layer into an upsampling layer for our decoder. ReLU is used as the activation function for the first two convolutions, while the sigmoid function is used for the final convolution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEDecoder(nn.Module):\n",
    "    def __init__(self, img_channels=1, num_filters=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build the CNN layers\n",
    "        self.conv0 = nn.Conv2d(in_channels=num_filters, out_channels=num_filters, kernel_size=3, padding='same')\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_filters, out_channels=img_channels, kernel_size=3, padding='same')\n",
    "        # Build the activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # Build the Upsampling layer\n",
    "        self.upsample0 = nn.Upsample(size=(14,14))\n",
    "        self.upsample1 = nn.Upsample(size=(28,28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First Convolutional Layer\n",
    "        y = self.conv0(x)\n",
    "        y = self.relu(y)\n",
    "        y = self.upsample0(y)\n",
    "\n",
    "        # Second Convolutional Layer\n",
    "        y = self.conv0(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.upsample1(y)\n",
    "\n",
    "        # Second Convolutional Layer\n",
    "        y = self.conv1(y)\n",
    "        y = self.sigmoid(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: In getting the correct sizes for the Upsampling layer, we can determine this by extracting the output shape of each layer for a random tensor.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape 0: torch.Size([5, 1, 28, 28])\n",
      "Shape 1: torch.Size([5, 32, 28, 28])\n",
      "Shape 2: torch.Size([5, 32, 14, 14])\n",
      "Shape 3: torch.Size([5, 32, 14, 14])\n",
      "Shape 4: torch.Size([5, 32, 7, 7])\n",
      "Shape 6: torch.Size([5, 32, 7, 7])\n",
      "Shape 7: torch.Size([5, 32, 14, 14])\n",
      "Shape 8: torch.Size([5, 32, 14, 14])\n",
      "Shape 9: torch.Size([5, 32, 28, 28])\n",
      "Shape 10: torch.Size([5, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "conv0 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding='same')\n",
    "conv1 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding='same')\n",
    "relu = nn.ReLU()\n",
    "maxpool0 = nn.MaxPool2d(kernel_size=2)\n",
    "maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "x = torch.randn(5, 1, 28, 28)\n",
    "print(f'Shape 0: {x.shape}')\n",
    "y = relu(conv0(x))\n",
    "print(f'Shape 1: {y.shape}')\n",
    "y = maxpool0(y)\n",
    "print(f'Shape 2: {y.shape}')\n",
    "y = relu(conv1(y))\n",
    "print(f'Shape 3: {y.shape}')\n",
    "y = maxpool1(y)\n",
    "print(f'Shape 4: {y.shape}')\n",
    "\n",
    "\n",
    "conv0 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding='same')\n",
    "conv1 = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=3, padding='same')\n",
    "sigmoid = nn.Sigmoid()\n",
    "upsample0 = nn.Upsample(size=(14,14))\n",
    "upsample1 = nn.Upsample(size=(28,28))\n",
    "y = relu(conv0(y))\n",
    "print(f'Shape 6: {y.shape}')\n",
    "y = upsample0(y)\n",
    "print(f'Shape 7: {y.shape}')\n",
    "y = relu(conv0(y))\n",
    "print(f'Shape 8: {y.shape}')\n",
    "y = upsample1(y)\n",
    "print(f'Shape 9: {y.shape}')\n",
    "y = sigmoid(conv1(y))\n",
    "print(f'Shape 10: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the noise that we will introduce to our train and test data through the collate_fn function. For this experiment, we applied a Gaussian noise with a mean of $0.0$ and a standard deviation of $1.0$ multiplied by the noise_factor, which is $0.5$ in this specific setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_collate_fn(batch):\n",
    "    x, _ = zip(*batch)\n",
    "    x = torch.stack(x, dim=0)\n",
    "    noise = 0.5 * torch.normal(mean=0., std=1., size=x.shape)\n",
    "    xn = x + noise\n",
    "    xn = torch.clip(xn, 0, 1)\n",
    "    return xn, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform the necessary preparations for the dataset and training, using the PyTorch Lightning module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDenoiseAEModel(pl.LightningModule):\n",
    "    def __init__(self, lr=0.001, batch_size=64, num_workers=4, max_epochs=30, num_filters=32, encoder=AEEncoder, decoder=AEDecoder, optim=\"adam\"):\n",
    "        # Initiate LightningModule superclass\n",
    "        super().__init__()\n",
    "        self.train_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "        # Set up other parameters\n",
    "        self.save_hyperparameters()\n",
    "        self.encoder = encoder(num_filters=num_filters)\n",
    "        self.decoder = decoder(num_filters=num_filters)\n",
    "        # Set up loss function (Mean Squared Error) and accuracy\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.optim = optim \n",
    "\n",
    "    def forward(self,x):\n",
    "        h = self.encoder(x)\n",
    "        return self.decoder(h)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        xn, x = batch\n",
    "        y = self.forward(xn)\n",
    "        loss = self.loss(y, x)\n",
    "        self.train_step_outputs.append({\"loss\": loss})\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in self.train_step_outputs]).mean()\n",
    "        print(f'Train loss: {avg_loss}')\n",
    "        self.train_step_outputs.clear()\n",
    "        self.log(\"train_loss\", avg_loss, on_epoch=True)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        xn, x = batch\n",
    "        y = self.forward(xn)\n",
    "        loss = self.loss(y, x)\n",
    "        self.test_step_outputs.append({\"xn\": xn, \"y\": y, \"test_loss\": loss})\n",
    "        return xn, y, loss\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        avg_loss = torch.stack([x[\"test_loss\"] for x in self.test_step_outputs]).mean()\n",
    "        print(f'Test loss: {avg_loss}')\n",
    "        self.test_step_outputs.clear()\n",
    "        self.log(\"test_loss\", avg_loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "       return self.test_step(batch, batch_idx)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        return self.on_test_epoch_end()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        if self.optim == \"adam\":\n",
    "            optimizer = Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        elif self.optim == \"sgd\":\n",
    "            optimizer = SGD(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    # Settings from https://nextjournal.com/gkoehler/pytorch-mnist\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                                        transform=torchvision.transforms.ToTensor()), \n",
    "                                        batch_size=self.hparams.batch_size, shuffle=True, pin_memory=True, collate_fn=noise_collate_fn)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                                        transform=torchvision.transforms.ToTensor()), \n",
    "                                        batch_size=self.hparams.batch_size, shuffle=False, pin_memory=True, collate_fn=noise_collate_fn)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.test_dataloader()\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataloader()\n",
    "        self.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up the model, the datasets, and the train/test/validation configurations, we set up the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = ArgumentParser(description=\"PyTorch Lightning MNIST Example\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=30, help=\"num epochs\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=64, help=\"batch size\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.001, help=\"learning rate\")\n",
    "    parser.add_argument(\"--num_filters\", default=32, help=\"num filters\")\n",
    "\n",
    "    parser.add_argument(\"--optim\", default=\"adam\", help=\"optimizer\")\n",
    "    # Verify device count with torch.cuda.device_count()\n",
    "    parser.add_argument(\"--devices\", default=1)\n",
    "    # Verify CUDA availability with torch.cuda.is_available())\n",
    "    parser.add_argument(\"--accelerator\", default='gpu')\n",
    "    # Recommended: num_workers = (os.cpu_count() // 2) // torch.cuda.device_count()\n",
    "    parser.add_argument(\"--num-workers\", type=int, default=4, help=\"num workers\")\n",
    "\n",
    "    parser.add_argument(\"--encoder\", default=AEEncoder)\n",
    "    parser.add_argument(\"--decoder\", default=AEDecoder)\n",
    "    parser.add_argument(\"--path\", default=\"models\", help=\"Model save path\")\n",
    "    args = parser.parse_args(\"\")\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train the Autoencoder model with the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type      | Params\n",
      "--------------------------------------\n",
      "0 | encoder | AEEncoder | 9.6 K \n",
      "1 | decoder | AEDecoder | 9.5 K \n",
      "2 | loss    | BCELoss   | 0     \n",
      "--------------------------------------\n",
      "19.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.1 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTDenoiseAEModel(\n",
      "  (encoder): AEEncoder(\n",
      "    (conv0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (relu): ReLU()\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): AEDecoder(\n",
      "    (conv0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (conv1): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (relu): ReLU()\n",
      "    (sigmoid): Sigmoid()\n",
      "    (upsample0): Upsample(size=(14, 14), mode='nearest')\n",
      "    (upsample1): Upsample(size=(28, 28), mode='nearest')\n",
      "  )\n",
      "  (loss): BCELoss()\n",
      ")\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 167.11it/s]Test loss: 0.6836158037185669\n",
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 938/938 [00:10<00:00, 91.20it/s, v_num=5]Test loss: 0.11185727268457413\n",
      "Epoch 0: 100%|██████████| 938/938 [00:11<00:00, 79.43it/s, v_num=5, test_loss=0.112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 938: 'test_loss' reached 0.11186 (best 0.11186), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.14627404510974884\n",
      "Epoch 1: 100%|██████████| 938/938 [00:10<00:00, 86.92it/s, v_num=5, test_loss=0.112]Test loss: 0.10489355772733688\n",
      "Epoch 1: 100%|██████████| 938/938 [00:12<00:00, 76.34it/s, v_num=5, test_loss=0.105]Train loss: 0.10924789309501648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1876: 'test_loss' reached 0.10489 (best 0.10489), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 938/938 [00:11<00:00, 83.11it/s, v_num=5, test_loss=0.105]Test loss: 0.10213672369718552\n",
      "Epoch 2: 100%|██████████| 938/938 [00:12<00:00, 72.68it/s, v_num=5, test_loss=0.102]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2814: 'test_loss' reached 0.10214 (best 0.10214), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10466042906045914\n",
      "Epoch 3: 100%|██████████| 938/938 [00:11<00:00, 83.25it/s, v_num=5, test_loss=0.102]Test loss: 0.10038948804140091\n",
      "Epoch 3: 100%|██████████| 938/938 [00:12<00:00, 72.44it/s, v_num=5, test_loss=0.100]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 3752: 'test_loss' reached 0.10039 (best 0.10039), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1023128479719162\n",
      "Epoch 4: 100%|██████████| 938/938 [00:11<00:00, 83.27it/s, v_num=5, test_loss=0.100]Test loss: 0.10000091046094894\n",
      "Epoch 4: 100%|██████████| 938/938 [00:12<00:00, 72.58it/s, v_num=5, test_loss=0.100]Train loss: 0.10090284794569016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 4690: 'test_loss' reached 0.10000 (best 0.10000), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 938/938 [00:11<00:00, 82.28it/s, v_num=5, test_loss=0.100]Test loss: 0.09828738868236542\n",
      "Epoch 5: 100%|██████████| 938/938 [00:13<00:00, 71.72it/s, v_num=5, test_loss=0.0983]Train loss: 0.09993486851453781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 5628: 'test_loss' reached 0.09829 (best 0.09829), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 938/938 [00:11<00:00, 82.24it/s, v_num=5, test_loss=0.0983]Test loss: 0.09772443771362305\n",
      "Epoch 6: 100%|██████████| 938/938 [00:13<00:00, 71.71it/s, v_num=5, test_loss=0.0977]Train loss: 0.09921788424253464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 6566: 'test_loss' reached 0.09772 (best 0.09772), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 938/938 [00:11<00:00, 81.17it/s, v_num=5, test_loss=0.0977]Test loss: 0.09783191233873367\n",
      "Epoch 7: 100%|██████████| 938/938 [00:13<00:00, 70.89it/s, v_num=5, test_loss=0.0978]Train loss: 0.09861350804567337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 7504: 'test_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 938/938 [00:11<00:00, 81.85it/s, v_num=5, test_loss=0.0978]Test loss: 0.09709092974662781\n",
      "Epoch 8: 100%|██████████| 938/938 [00:13<00:00, 71.42it/s, v_num=5, test_loss=0.0971]Train loss: 0.09840995818376541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 8442: 'test_loss' reached 0.09709 (best 0.09709), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 938/938 [00:11<00:00, 82.77it/s, v_num=5, test_loss=0.0971]Test loss: 0.09696917235851288\n",
      "Epoch 9: 100%|██████████| 938/938 [00:12<00:00, 72.19it/s, v_num=5, test_loss=0.097] Train loss: 0.09794747084379196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 9380: 'test_loss' reached 0.09697 (best 0.09697), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 938/938 [00:11<00:00, 82.75it/s, v_num=5, test_loss=0.097]Test loss: 0.09696970134973526\n",
      "Epoch 10: 100%|██████████| 938/938 [00:12<00:00, 72.17it/s, v_num=5, test_loss=0.097]Train loss: 0.09764152020215988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 10318: 'test_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 938/938 [00:11<00:00, 82.43it/s, v_num=5, test_loss=0.097]Test loss: 0.09631510078907013\n",
      "Epoch 11: 100%|██████████| 938/938 [00:13<00:00, 71.97it/s, v_num=5, test_loss=0.0963]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 11256: 'test_loss' reached 0.09632 (best 0.09632), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09740780293941498\n",
      "Epoch 12: 100%|██████████| 938/938 [00:11<00:00, 82.41it/s, v_num=5, test_loss=0.0963]Test loss: 0.09618654102087021\n",
      "Epoch 12: 100%|██████████| 938/938 [00:13<00:00, 71.78it/s, v_num=5, test_loss=0.0962]Train loss: 0.09721986204385757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 12194: 'test_loss' reached 0.09619 (best 0.09619), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 938/938 [00:11<00:00, 83.73it/s, v_num=5, test_loss=0.0962]Test loss: 0.09628179669380188\n",
      "Epoch 13: 100%|██████████| 938/938 [00:12<00:00, 73.13it/s, v_num=5, test_loss=0.0963]Train loss: 0.09699399024248123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 13132: 'test_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 938/938 [00:11<00:00, 84.56it/s, v_num=5, test_loss=0.0963]Test loss: 0.09586665779352188\n",
      "Epoch 14: 100%|██████████| 938/938 [00:12<00:00, 73.55it/s, v_num=5, test_loss=0.0959]Train loss: 0.0968688502907753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 14070: 'test_loss' reached 0.09587 (best 0.09587), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 938/938 [00:11<00:00, 83.85it/s, v_num=5, test_loss=0.0959]Test loss: 0.09567689895629883\n",
      "Epoch 15: 100%|██████████| 938/938 [00:12<00:00, 73.30it/s, v_num=5, test_loss=0.0957]Train loss: 0.09674866497516632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 15008: 'test_loss' reached 0.09568 (best 0.09568), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 938/938 [00:11<00:00, 84.62it/s, v_num=5, test_loss=0.0957]Test loss: 0.09571661055088043\n",
      "Epoch 16: 100%|██████████| 938/938 [00:12<00:00, 73.89it/s, v_num=5, test_loss=0.0957]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 15946: 'test_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09661473333835602\n",
      "Epoch 17: 100%|██████████| 938/938 [00:11<00:00, 83.71it/s, v_num=5, test_loss=0.0957]Test loss: 0.09560659527778625\n",
      "Epoch 17: 100%|██████████| 938/938 [00:12<00:00, 72.63it/s, v_num=5, test_loss=0.0956]Train loss: 0.09647990763187408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 16884: 'test_loss' reached 0.09561 (best 0.09561), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 938/938 [00:11<00:00, 84.59it/s, v_num=5, test_loss=0.0956]Test loss: 0.09563414752483368\n",
      "Epoch 18: 100%|██████████| 938/938 [00:12<00:00, 73.83it/s, v_num=5, test_loss=0.0956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 17822: 'test_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09641473740339279\n",
      "Epoch 19: 100%|██████████| 938/938 [00:11<00:00, 84.58it/s, v_num=5, test_loss=0.0956]Test loss: 0.09559273719787598\n",
      "Epoch 19: 100%|██████████| 938/938 [00:12<00:00, 73.82it/s, v_num=5, test_loss=0.0956]Train loss: 0.0963536873459816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 18760: 'test_loss' reached 0.09559 (best 0.09559), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 938/938 [00:11<00:00, 84.60it/s, v_num=5, test_loss=0.0956]Test loss: 0.09550080448389053\n",
      "Epoch 20: 100%|██████████| 938/938 [00:12<00:00, 73.76it/s, v_num=5, test_loss=0.0955]Train loss: 0.09627275913953781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 19698: 'test_loss' reached 0.09550 (best 0.09550), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 938/938 [00:11<00:00, 84.65it/s, v_num=5, test_loss=0.0955]Test loss: 0.09529144316911697\n",
      "Epoch 21: 100%|██████████| 938/938 [00:12<00:00, 73.87it/s, v_num=5, test_loss=0.0953]Train loss: 0.09615650027990341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 20636: 'test_loss' reached 0.09529 (best 0.09529), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 938/938 [00:11<00:00, 84.37it/s, v_num=5, test_loss=0.0953]Test loss: 0.09515062719583511\n",
      "Epoch 22: 100%|██████████| 938/938 [00:12<00:00, 73.44it/s, v_num=5, test_loss=0.0952]Train loss: 0.0961398258805275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 21574: 'test_loss' reached 0.09515 (best 0.09515), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 938/938 [00:11<00:00, 82.98it/s, v_num=5, test_loss=0.0952]Test loss: 0.09524589031934738\n",
      "Epoch 23: 100%|██████████| 938/938 [00:12<00:00, 72.35it/s, v_num=5, test_loss=0.0952]Train loss: 0.0960787981748581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 22512: 'test_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 938/938 [00:11<00:00, 82.59it/s, v_num=5, test_loss=0.0952]Test loss: 0.09492850303649902\n",
      "Epoch 24: 100%|██████████| 938/938 [00:13<00:00, 71.87it/s, v_num=5, test_loss=0.0949]Train loss: 0.09597466140985489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 23450: 'test_loss' reached 0.09493 (best 0.09493), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 938/938 [00:11<00:00, 82.19it/s, v_num=5, test_loss=0.0949]Test loss: 0.09508170187473297\n",
      "Epoch 25: 100%|██████████| 938/938 [00:13<00:00, 71.76it/s, v_num=5, test_loss=0.0951]Train loss: 0.09599713236093521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 24388: 'test_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 938/938 [00:11<00:00, 80.34it/s, v_num=5, test_loss=0.0951]Test loss: 0.09504222869873047\n",
      "Epoch 26: 100%|██████████| 938/938 [00:13<00:00, 69.69it/s, v_num=5, test_loss=0.095] Train loss: 0.09599431604146957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 25326: 'test_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 938/938 [00:13<00:00, 71.11it/s, v_num=5, test_loss=0.095]Test loss: 0.09521403163671494\n",
      "Epoch 27: 100%|██████████| 938/938 [00:14<00:00, 62.58it/s, v_num=5, test_loss=0.0952]Train loss: 0.09594899415969849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 26264: 'test_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 938/938 [00:12<00:00, 75.19it/s, v_num=5, test_loss=0.0952]Test loss: 0.09509976208209991\n",
      "Epoch 28: 100%|██████████| 938/938 [00:14<00:00, 65.90it/s, v_num=5, test_loss=0.0951]Train loss: 0.09592968225479126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 27202: 'test_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 938/938 [00:12<00:00, 73.83it/s, v_num=5, test_loss=0.0951]Test loss: 0.09492790699005127\n",
      "Epoch 29: 100%|██████████| 938/938 [00:14<00:00, 65.22it/s, v_num=5, test_loss=0.0949]Train loss: 0.09593285620212555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 28140: 'test_loss' reached 0.09493 (best 0.09493), saving model to 'C:\\\\Users\\\\Dave\\\\Documents\\\\Experiments\\\\deep-learning\\\\AE\\\\models\\\\checkpoints\\\\mnist-ae-best-acc.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 938/938 [00:14<00:00, 65.11it/s, v_num=5, test_loss=0.0949]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 116.87it/s]Test loss: 0.09500822424888611\n",
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 116.35it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.09500822424888611\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = get_args()\n",
    "    model = MNISTDenoiseAEModel(lr=args.lr, batch_size=args.batch_size,\n",
    "                           num_workers=args.num_workers, num_filters=args.num_filters,\n",
    "                           encoder=args.encoder, decoder=args.decoder, optim=args.optim)\n",
    "    model.setup()\n",
    "    print(model)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        dirpath=os.path.join(args.path, \"checkpoints\"),\n",
    "        filename=\"mnist-ae-best-acc\",\n",
    "        save_top_k=1,\n",
    "        verbose=True,\n",
    "        monitor='test_loss',\n",
    "        mode='min')\n",
    "\n",
    "    trainer = pl.Trainer(accelerator=args.accelerator,\n",
    "                      devices=args.devices,\n",
    "                      max_epochs=args.epochs,\n",
    "                      callbacks=model_checkpoint)\n",
    "\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model)\n",
    "\n",
    "    model = model.load_from_checkpoint(os.path.join(args.path, \"checkpoints\", \"mnist-ae-best-acc.ckpt\"))\n",
    "    model.eval()\n",
    "    script = model.to_torchscript()\n",
    "    model_path = os.path.join(args.path, \"checkpoints\", \"mnist-ae-best-acc.pt\")\n",
    "    torch.jit.save(script, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "* We have observed that test loss gradually decreases to each epoch, which ultimately goes down to a final net loss of around $0.095$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference of the trained model on handwritten digits\n",
    "Now that we have successfully trained and saved the model, we use it for denoising noisy digit images. We used a noisy version of a handwritten digit $7$ and feed it into our autoencoder model. Upon observation, we have seen that the model properly denoises the image, leaving out only the important features that define the digit $7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scripted_module = torch.jit.load('models/checkpoints/mnist-ae-best-acc.pt')\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.Resize((28,28)),\n",
    "                                torchvision.transforms.ToTensor(),\n",
    "                                torchvision.transforms.Grayscale(num_output_channels=1)])\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(4, 2))\n",
    "  \n",
    "# setting values to rows and column variables\n",
    "rows = 1\n",
    "columns = 2\n",
    "\n",
    "img = Image.open('noisy_digit.png')\n",
    "img = img.convert('RGB')\n",
    "img = transform(img)\n",
    "img = torch.unsqueeze(img,0)\n",
    "img = img.to('cuda')\n",
    "denoised_img = scripted_module(img)\n",
    "denoised_img = torchvision.transforms.ToPILImage()(torch.squeeze(denoised_img))\n",
    "img = torchvision.transforms.ToPILImage()(torch.squeeze(img))\n",
    "\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Input Image\")\n",
    "\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(denoised_img, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Denoised Image\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
